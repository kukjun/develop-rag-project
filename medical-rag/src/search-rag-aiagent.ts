import "dotenv/config";
import { OpenAIEmbeddings } from "@langchain/openai";
import { ChatOpenAI } from "@langchain/openai";
import { PGVectorStore } from "@langchain/community/vectorstores/pgvector";
import { createReactAgent } from "@langchain/langgraph/prebuilt";
import { logger } from "./utils/logger";
import { z } from "zod";
import { tool } from "@langchain/core/tools";

/**
 * PGVector ì´ˆê¸°í™” ë° Retrieve Tool ìƒì„±
 */
async function createRetrieveTool() {
  // OpenAI Embeddings ì´ˆê¸°í™”
  const embeddings = new OpenAIEmbeddings({
    openAIApiKey: process.env.OPENAI_API_KEY,
    modelName: "text-embedding-3-small",
  });

  // PGVector ì„¤ì •
  const config = {
    postgresConnectionOptions: {
      type: "postgres",
      host: process.env.PGVECTOR_HOST || "localhost",
      port: parseInt(process.env.PGVECTOR_PORT || "5433"),
      user: process.env.PGVECTOR_USER || "postgres",
      password: process.env.PGVECTOR_PASSWORD || "password",
      database: process.env.PGVECTOR_DATABASE || "medical_rag",
    },
    tableName: "medical_rag_embeddings",
    columns: {
      idColumnName: "id",
      vectorColumnName: "embedding",
      contentColumnName: "content",
      metadataColumnName: "metadata",
    },
  };

  // PGVector ì—°ê²°
  logger.info("Connecting to PGVector...");
  const vectorStore = await PGVectorStore.initialize(embeddings, config);
  logger.info("âœ“ PGVector connected");

  // Retrieve Tool ìƒì„±
  const retrieveSchema = z.object({ query: z.string() });

  // @ts-ignore - LangGraph íƒ€ì… ì¶”ë¡  ê¹Šì´ ë¬¸ì œ
  const retrieve = tool(
    async ({ query }) => {
      const retrievedDocs = await vectorStore.similaritySearch(query, 3);
      const serialized = retrievedDocs
        .map(
          (doc) =>
            `Source: ${doc.metadata.disease_name || "Unknown"}\nContent: ${
              doc.pageContent
            }`
        )
        .join("\n\n");
      return [serialized, retrievedDocs];
    },
    {
      name: "retrieve_medical_info",
      description:
        "ì˜ë£Œ ì •ë³´ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.",
      schema: retrieveSchema,
      responseFormat: "content_and_artifact",
    }
  );

  return retrieve;
}

/**
 * AI Agentë¥¼ ì´ìš©í•œ RAG ê¸°ë°˜ ë‹µë³€ ìƒì„±
 */
async function generateAnswerWithAgent(query: string): Promise<string> {
  const totalStartTime = Date.now();
  logger.info("\nğŸ¤– Creating AI Agent with retrieve tool...");

  // 1. Retrieve Tool ìƒì„±
  const toolStartTime = Date.now();
  const retrieveTool = await createRetrieveTool();
  logger.info(`âœ“ Tool created (${Date.now() - toolStartTime}ms)`);

  // 2. System prompt êµ¬ì„±
  const systemPrompt = `ë‹¹ì‹ ì€ ì˜ë£Œ ì •ë³´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

# ë‹µë³€ ì§€ì¹¨
- ì˜í•™ ê´€ë ¨ëœ ì§ˆë¬¸ì´ ì˜¤ë©´, ë°˜ë“œì‹œ retrieve_medical_info ë„êµ¬ë¡œ ê´€ë ¨ ë¬¸ì„œë¥¼ ë¨¼ì € ê²€ìƒ‰í•˜ì„¸ìš”.
- ì˜í•™ê³¼ ê´€ë ¨ë˜ì§€ ì•Šì€ ì§ˆë¬¸ì€ ê·¸ëƒ¥ ë‹µë³€í•˜ì„¸ìš”.
- ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ë‚´ìš©ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
- ì˜í•™ì ìœ¼ë¡œ ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ë§Œ ì œê³µí•˜ì„¸ìš”
- ê²€ìƒ‰ ê²°ê³¼ì— ì—†ëŠ” ë‚´ìš©ì€ "ì œê³µëœ ë¬¸ì„œì—ëŠ” í•´ë‹¹ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”
- í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ë‹µë³€í•˜ì„¸ìš”
- ê²€ìƒ‰í•œ ë¬¸ì„œì˜ ì¶œì²˜ë¥¼ ì–¸ê¸‰í•˜ì„¸ìš”`;

  // 3. LLM ì´ˆê¸°í™” (Chat ëª¨ë¸ ì‚¬ìš©)
  logger.info("â³ Initializing LLM...");
  const llmStartTime = Date.now();
  const llm = new ChatOpenAI({
    openAIApiKey: process.env.OPENAI_API_KEY,
    modelName: "gpt-5-nano",
    temperature: 1,
  });
  logger.info(`âœ“ LLM initialized (${Date.now() - llmStartTime}ms)`);

  // 4. React Agent ìƒì„± (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ Agent ì„¤ì •ì— í¬í•¨)
  logger.info("â³ Creating React Agent...");
  const agentStartTime = Date.now();
  // @ts-ignore - LangGraph íƒ€ì… ì¶”ë¡  ê¹Šì´ ë¬¸ì œ
  const agent = createReactAgent({
    llm,
    tools: [retrieveTool],
    messageModifier: systemPrompt, // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ Agentì— ë¯¸ë¦¬ ì„¤ì •
  });
  logger.info(`âœ“ Agent created (${Date.now() - agentStartTime}ms)`);
  logger.info(`â±ï¸  Total setup time: ${Date.now() - totalStartTime}ms`);

  // 5. Agent ì‹¤í–‰ (ì‚¬ìš©ì ì…ë ¥ë§Œ ì „ë‹¬) - ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ê° ë‹¨ê³„ í™•ì¸
  logger.info("\nğŸ”„ Agent is processing your query...\n");

  const stream = await agent.stream(
    { messages: [{ role: "user", content: query }] },
    { streamMode: "values" }
  );

  let finalAnswer = "";

  // ê° ë‹¨ê³„ì˜ ë©”ì‹œì§€ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸
  for await (const step of stream) {
    const lastMessage = step.messages[step.messages.length - 1];
    const messageType = lastMessage._getType();

    logger.info(`\n${"=".repeat(60)}`);
    logger.info(`ğŸ“¨ Step ${step.messages.length}: ${messageType}`);

    // ì „ì²´ ë©”ì‹œì§€ êµ¬ì¡° ì¶œë ¥ (ë””ë²„ê¹…)
    logger.info(`ğŸ” Full message structure:`);
    logger.info(
      JSON.stringify(
        {
          type: messageType,
          content: lastMessage.content,
          tool_calls: lastMessage.tool_calls,
          name: lastMessage.name,
          additional_kwargs: lastMessage.additional_kwargs,
        },
        null,
        2
      )
    );

    // Tool í˜¸ì¶œ ì—¬ë¶€ í™•ì¸
    if (
      messageType === "ai" &&
      lastMessage.tool_calls &&
      lastMessage.tool_calls.length > 0
    ) {
      logger.info(`\nğŸ”§ Tool Called: ${lastMessage.tool_calls[0].name}`);
      logger.info(
        `   Arguments: ${JSON.stringify(lastMessage.tool_calls[0].args)}`
      );
    }

    // Toolì˜ ì‘ë‹µ í™•ì¸
    if (messageType === "tool") {
      const content =
        typeof lastMessage.content === "string"
          ? lastMessage.content
          : JSON.stringify(lastMessage.content);
      logger.info(`\nğŸ“¦ [Tool Response]: ${content.substring(0, 300)}...`);
    }

    // AIì˜ ìµœì¢… ì‘ë‹µ í™•ì¸ (tool_callsê°€ ì—†ê±°ë‚˜ ë¹ˆ ë°°ì—´ì¸ ê²½ìš°)
    if (
      messageType === "ai" &&
      (!lastMessage.tool_calls || lastMessage.tool_calls.length === 0)
    ) {
      const content =
        typeof lastMessage.content === "string"
          ? lastMessage.content
          : Array.isArray(lastMessage.content)
          ? lastMessage.content.map((c) => c.text || c).join("")
          : JSON.stringify(lastMessage.content);

      logger.info(`\nğŸ¤– [AI Final Answer]:`);
      logger.info(content);

      if (content && content.length > 0) {
        finalAnswer = content;
      }
    }
  }

  logger.info("\n" + "=".repeat(60));

  return finalAnswer;
}

/**
 * ë©”ì¸ ì‹¤í–‰
 */
async function main() {
  const mainStartTime = Date.now();
  try {
    logger.info("=".repeat(60));
    logger.info("Medical RAG with AI Agent & PGVector");
    logger.info("=".repeat(60));

    // í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    const query = "ê¹€ì¹˜ì°Œê°œ ì˜ ë“ì´ëŠ” ë²•";

    logger.info(`\nâ“ Query: ${query}\n`);

    // AI Agentë¡œ ë‹µë³€ ìƒì„± (ìë™ìœ¼ë¡œ retrieve tool í˜¸ì¶œ)
    const agentStartTime = Date.now();
    const answer = await generateAnswerWithAgent(query);
    logger.info(`\nâ±ï¸  Agent execution time: ${Date.now() - agentStartTime}ms`);

    logger.info("\nğŸ“ Final Answer:");
    logger.info("=".repeat(60));
    logger.info(answer);
    logger.info("=".repeat(60));
    logger.info(`\nâ±ï¸  Total execution time: ${Date.now() - mainStartTime}ms`);
  } catch (error) {
    logger.error("Search failed:", error);
    process.exit(1);
  }
}

// ì‹¤í–‰
main();
