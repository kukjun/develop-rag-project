import "dotenv/config";
import { OpenAIEmbeddings } from "@langchain/openai";
import { ChatOpenAI } from "@langchain/openai";
import { PGVectorStore } from "@langchain/community/vectorstores/pgvector";
import { logger } from "./utils/logger";

/**
 * PGVector ì´ˆê¸°í™”
 */
async function initializeVectorStore() {
  const embeddings = new OpenAIEmbeddings({
    openAIApiKey: process.env.OPENAI_API_KEY,
    modelName: "text-embedding-3-small",
  });

  const config = {
    postgresConnectionOptions: {
      type: "postgres",
      host: process.env.PGVECTOR_HOST || "localhost",
      port: parseInt(process.env.PGVECTOR_PORT || "5433"),
      user: process.env.PGVECTOR_USER || "postgres",
      password: process.env.PGVECTOR_PASSWORD || "password",
      database: process.env.PGVECTOR_DATABASE || "medical_rag",
    },
    tableName: "medical_rag_embeddings",
    columns: {
      idColumnName: "id",
      vectorColumnName: "embedding",
      contentColumnName: "content",
      metadataColumnName: "metadata",
    },
  };

  logger.info("Connecting to PGVector...");
  const vectorStore = await PGVectorStore.initialize(embeddings, config);
  logger.info("âœ“ PGVector connected");

  return vectorStore;
}

/**
 * RAG ê¸°ë°˜ ë‹µë³€ ìƒì„± (Tool ì—†ì´ ì§ì ‘ ê²€ìƒ‰)
 */
async function generateAnswer(query: string): Promise<string> {
  const totalStartTime = Date.now();

  // 1. VectorStore ì´ˆê¸°í™”
  const vectorStore = await initializeVectorStore();

  // 2. ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
  logger.info("\nğŸ” Searching for relevant documents...");
  const searchStartTime = Date.now();
  const retrievedDocs = await vectorStore.similaritySearch(query, 3);
  logger.info(
    `âœ“ Found ${retrievedDocs.length} documents (${
      Date.now() - searchStartTime
    }ms)`
  );

  // 3. ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±
  const context = retrievedDocs
    .map(
      (doc, idx) =>
        `[ë¬¸ì„œ ${idx + 1}]\nì¶œì²˜: ${
          doc.metadata.disease_name || "Unknown"
        }\në‚´ìš©: ${doc.pageContent}`
    )
    .join("\n\n");

  logger.info("\nğŸ“„ Retrieved Context:");
  logger.info(context);

  // 4. LLM ì´ˆê¸°í™”
  logger.info("â³ Initializing LLM...");
  const llm = new ChatOpenAI({
    openAIApiKey: process.env.OPENAI_API_KEY,
    modelName: "gpt-5-nano",
    temperature: 1,
  });

  // 5. í”„ë¡¬í”„íŠ¸ êµ¬ì„± ë° ë‹µë³€ ìƒì„±
  logger.info("â³ Generating answer...");
  const prompt = `ë‹¹ì‹ ì€ ì˜ë£Œ ì •ë³´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

# ë‹µë³€ ì§€ì¹¨
- ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ë‚´ìš©ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
- ì˜í•™ì ìœ¼ë¡œ ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ë§Œ ì œê³µí•˜ì„¸ìš”
- ê²€ìƒ‰ ê²°ê³¼ì— ì—†ëŠ” ë‚´ìš©ì€ "ì œê³µëœ ë¬¸ì„œì—ëŠ” í•´ë‹¹ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”
- í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ë‹µë³€í•˜ì„¸ìš”
- ë‹µë³€ ëì— ì°¸ê³ í•œ ë¬¸ì„œì˜ ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ì„¸ìš”

# ê²€ìƒ‰ëœ ë¬¸ì„œ
${context}

# ì‚¬ìš©ì ì§ˆë¬¸
${query}

# ë‹µë³€`;

  const answerStartTime = Date.now();
  const response = await llm.invoke(prompt);
  logger.info(`âœ“ Answer generated (${Date.now() - answerStartTime}ms)`);
  logger.info(`â±ï¸  Total execution time: ${Date.now() - totalStartTime}ms`);

  return response.content as string;
}

/**
 * ë©”ì¸ ì‹¤í–‰
 */
async function main() {
  const mainStartTime = Date.now();
  try {
    logger.info("=".repeat(60));
    logger.info("Medical RAG with Direct Search");
    logger.info("=".repeat(60));

    // í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    const query = "ëŒ€ì¥ì•”ì˜ ì¦ìƒì€ ë¬´ì—‡ì¸ê°€ìš”?";

    logger.info(`\nâ“ Query: ${query}\n`);

    // RAGë¡œ ë‹µë³€ ìƒì„±
    const answer = await generateAnswer(query);

    logger.info("\nğŸ“ Final Answer:");
    logger.info("=".repeat(60));
    logger.info(answer);
    logger.info("=".repeat(60));
    logger.info(`\nâ±ï¸  Total execution time: ${Date.now() - mainStartTime}ms`);
  } catch (error) {
    logger.error("Search failed:", error);
    process.exit(1);
  }
}

// ì‹¤í–‰
main();
